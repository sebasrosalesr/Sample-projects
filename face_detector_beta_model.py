# -*- coding: utf-8 -*-
"""Copy of Face detector beta model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WKtrR60hftJKaqQJ2aij5EJFkxh3vVvO
"""

# Define the base path to your image directory
base_path = '/content/drive/MyDrive/Deep Learning Projects/r_projects /f_project/train/'

# Ensure there are no leading or trailing whitespaces
base_path = base_path.strip()

# Ensure the base path ends with a single slash
if not base_path.endswith('/'):
    base_path += '/'

# Print the base path to verify
print(f"Base path: {base_path}")

import pandas as pd
import os

# Load the CSV file
csv_file = '/content/drive/MyDrive/Deep Learning Projects/r_projects /f_project/label_data.csv'  # Replace with the path to your CSV file
data = pd.read_csv(csv_file)

# Use the correct base path
base_path = '/content/drive/MyDrive/Deep Learning Projects/r_projects /f_project/train/'

# Create the full image paths
data['image_path'] = data['id'].apply(lambda x: os.path.join(base_path, x.strip()))

# Print the first few image paths to verify
print(data['image_path'].head())

# Verify the existence of the files and collect valid paths
valid_image_paths = []
valid_labels = []

for image_path, label in zip(data['image_path'].values, data['label'].values):
    if os.path.exists(image_path):
        valid_image_paths.append(image_path)
        valid_labels.append(label)
    else:
        print(f"File not found: {image_path}")

# Display the number of valid and invalid paths
print(f"Valid image paths: {len(valid_image_paths)}")
print(f"Invalid image paths: {len(data) - len(valid_image_paths)}")

# Optionally, create a new DataFrame with valid paths only
valid_data = pd.DataFrame({'image_path': valid_image_paths, 'label': valid_labels})
print(valid_data.head())

import pandas as pd
import os

# Load the CSV file
csv_file = '/content/drive/MyDrive/Deep Learning Projects/r_projects /f_project/label_data.csv'  # Replace with the path to your CSV file
data = pd.read_csv(csv_file)

# Correct the base path to your image directory
base_path = '/content/drive/MyDrive/Deep Learning Projects/r_projects /f_project/train/'
base_path = base_path.rstrip('/') + '/'  # Ensure the base path ends with a single slash

# Create the full image paths
data['image_path'] = data['id'].apply(lambda x: os.path.join(base_path, x.strip()))

# Verify the existence of the files and collect valid paths
valid_image_paths = []
valid_labels = []
for image_path, label in zip(data['image_path'].values, data['label'].values):
    if os.path.exists(image_path):
        valid_image_paths.append(image_path)
        valid_labels.append(label)
    else:
        print(f"File not found: {image_path}")

# Display the number of valid and invalid paths
print(f"Valid image paths: {len(valid_image_paths)}")
print(f"Invalid image paths: {len(data) - len(valid_image_paths)}")

# Create a new DataFrame with valid paths only
valid_data = pd.DataFrame({'image_path': valid_image_paths, 'label': valid_labels})
print(valid_data.head())

# Remove invalid rows from the original dataset
data = data[data['image_path'].isin(valid_image_paths)]
print(data.head())

# Display the number of valid and invalid paths
print(f"Valid image paths: {len(valid_image_paths)}")
print(f"Invalid image paths: {len(data) - len(valid_image_paths)}")

import tensorflow as tf

# Function to load and preprocess an image
def load_image(image_path):
    image = tf.io.read_file(image_path)
    if tf.strings.regex_full_match(image_path, r".*\.(jpg|jpeg|JPG|JPEG)"):
        image = tf.image.decode_jpeg(image, channels=3)
    elif tf.strings.regex_full_match(image_path, r".*\.(png|PNG)"):
        image = tf.image.decode_png(image, channels=3)
    elif tf.strings.regex_full_match(image_path, r".*\.(gif|GIF)"):
        image = tf.image.decode_gif(image)
    elif tf.strings.regex_full_match(image_path, r".*\.(bmp|BMP)"):
        image = tf.image.decode_bmp(image)
    else:
        raise ValueError("Unsupported image format: " + image_path)

    image = tf.image.resize(image, [150, 150])
    image = image / 255.0  # Normalize to [0, 1]
    return image

def load_image_and_label(image_path, label):
    image = load_image(image_path)
    return image, label

# Convert labels to numeric
label_map = {label: idx for idx, label in enumerate(valid_data['label'].unique())}
valid_data['label'] = valid_data['label'].map(label_map)

# Convert to TensorFlow dataset
def load_image_and_label(image_path, label):
    image = load_image(image_path)
    return image, tf.convert_to_tensor(label, dtype=tf.int32)

# Create dataset from valid paths and labels
dataset = tf.data.Dataset.from_tensor_slices((valid_data['image_path'].values, valid_data['label'].values))
dataset = dataset.map(lambda x, y: tf.py_function(func=load_image_and_label, inp=[x, y], Tout=[tf.float32, tf.int32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)

# Ensure shapes are set correctly after using py_function
def set_shapes(img, label):
    img.set_shape([150, 150, 3])
    label.set_shape([])
    return img, label

dataset = dataset.map(set_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE)

# Shuffle and batch the dataset
dataset = dataset.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Split the dataset into training and validation sets
train_size = int(0.8 * len(valid_data))
train_dataset = dataset.take(train_size)
val_dataset = dataset.skip(train_size)

# Displaying the label map for reference
print("Label map:", label_map)

# Verify the existence of the files and collect valid paths, excluding unsupported formats
supported_formats = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')
valid_image_paths = []
valid_labels = []
for image_path, label in zip(data['image_path'].values, data['label'].values):
    if os.path.exists(image_path) and image_path.lower().endswith(supported_formats):
        valid_image_paths.append(image_path)
        valid_labels.append(label)
    else:
        print(f"File not found or unsupported format: {image_path}")

# Create a new DataFrame with valid paths only
valid_data = pd.DataFrame({'image_path': valid_image_paths, 'label': valid_labels})
print(f"Number of valid images: {len(valid_data)}")
print(valid_data.head())

# Ensure there are enough valid images
if len(valid_data) == 0:
    raise ValueError("No valid images found. Please check the dataset and file paths.")

# Function to load and preprocess an image
def load_image(image_path):
    image = tf.io.read_file(image_path)
    if tf.strings.regex_full_match(image_path, r".*\.(jpg|jpeg|JPG|JPEG)"):
        image = tf.image.decode_jpeg(image, channels=3)
    elif tf.strings.regex_full_match(image_path, r".*\.(png|PNG)"):
        image = tf.image.decode_png(image, channels=3)
    elif tf.strings.regex_full_match(image_path, r".*\.(gif|GIF)"):
        image = tf.image.decode_gif(image)
    elif tf.strings.regex_full_match(image_path, r".*\.(bmp|BMP)"):
        image = tf.image.decode_bmp(image)
    else:
        raise ValueError("Unsupported image format: " + image_path)

    image = tf.image.resize(image, [150, 150])
    image = image / 255.0  # Normalize to [0, 1]
    return image

def load_image_and_label(image_path, label):
    image = load_image(image_path)
    return image, tf.convert_to_tensor(label, dtype=tf.int32)  # Ensure label is int32

# Data augmentation function
def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, max_delta=0.1)
    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)
    return image, label

# Convert labels to numeric
label_map = {label: idx for idx, label in enumerate(valid_data['label'].unique())}
valid_data['label'] = valid_data['label'].map(label_map)

# Create dataset from valid paths and labels
def load_image_and_label(image_path, label):
    image = load_image(image_path)
    label = tf.cast(label, tf.int32)
    return image, label

# Create dataset from valid paths and labels
dataset = tf.data.Dataset.from_tensor_slices((valid_data['image_path'].values, valid_data['label'].values))
dataset = dataset.map(lambda x, y: tf.py_function(func=load_image_and_label, inp=[x, y], Tout=[tf.float32, tf.int32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)

# Apply data augmentation
dataset = dataset.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)

# Ensure shapes are set correctly after using py_function
def set_shapes(img, label):
    img.set_shape([150, 150, 3])
    label.set_shape([])
    return img, label

dataset = dataset.map(set_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE)

# Shuffle and batch the dataset
dataset = dataset.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Check if the training dataset is empty
print(f"Training dataset size: {len(list(dataset))}")

if len(list(dataset)) == 0:
    raise ValueError("Training dataset is empty. Please check the dataset.")

# Displaying the label map for reference
print("Label map:", label_map)

# Build the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(len(label_map), activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(
    dataset,  # Use all data for training
    epochs=50  # Increase the number of epochs
)

# Save the model
model.save('face_detection_model.h5')

# Load the saved model
model = tf.keras.models.load_model('face_detection_model.h5')

# Manually select a few images for evaluation
evaluation_image_paths = valid_data['image_path'].values[:5]
evaluation_labels = valid_data['label'].values[:5]

# Function to preprocess evaluation images
def preprocess_evaluation_images(image_paths, labels):
    images = []
    for image_path in image_paths:
        image = load_image(image_path)
        images.append(image)
    images = tf.stack(images)  # Stack the images into a single tensor
    labels = tf.convert_to_tensor(labels, dtype=tf.int32)  # Convert labels to tensor
    return images, labels

evaluation_images, evaluation_labels = preprocess_evaluation_images(evaluation_image_paths, evaluation_labels)

# Evaluate the model
evaluation_results = model.evaluate(evaluation_images, evaluation_labels, verbose=2)
print(f"Evaluation results - Loss: {evaluation_results[0]}, Accuracy: {evaluation_results[1]}")

# Function to make predictions on new images
def predict_image(image_path):
    image = load_image(image_path)
    image = tf.expand_dims(image, axis=0)  # Add batch dimension
    prediction = model.predict(image)
    predicted_label = tf.argmax(prediction, axis=1).numpy()[0]
    label_map_reverse = {v: k for k, v in label_map.items()}
    predicted_label_name = label_map_reverse[predicted_label]
    return predicted_label_name

# Example prediction
test_image_path = valid_data['image_path'].values[33]  # Use an image path from the dataset
predicted_label = predict_image(test_image_path)
print(f"Predicted label for the test image: {predicted_label}")

import matplotlib.pyplot as plt

# Function to make predictions on new images
def predict_image(image_path):
    image = load_image(image_path)
    image = tf.expand_dims(image, axis=0)  # Add batch dimension
    prediction = model.predict(image)
    predicted_label = tf.argmax(prediction, axis=1).numpy()[0]
    label_map_reverse = {v: k for k, v in label_map.items()}
    predicted_label_name = label_map_reverse[predicted_label]
    return predicted_label_name, image

# Function to display images with their predictions
def display_images_with_predictions(image_paths):
    plt.figure(figsize=(15, 10))
    for i, image_path in enumerate(image_paths):
        predicted_label, image = predict_image(image_path)
        image = tf.squeeze(image)  # Remove batch dimension
        plt.subplot(3, 3, i+1)
        plt.imshow(image)
        plt.title(f"Predicted: {predicted_label}")
        plt.axis('off')
    plt.show()

# Example usage: display predictions for the first 9 images
display_images_with_predictions(valid_data['image_path'].values[33:40])

"""## Web cam detector

"""

import cv2
import tensorflow as tf
import numpy as np
from datetime import datetime
import os

# Load the trained model
model = tf.keras.models.load_model('face_detection_model.h5')

# Function to preprocess a frame
def preprocess_frame(frame):
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame = cv2.resize(frame, (150, 150))
    frame = frame / 255.0
    frame = np.expand_dims(frame, axis=0)  # Add batch dimension
    return frame

# Function to make predictions on a frame
def predict_frame(frame):
    preprocessed_frame = preprocess_frame(frame)
    prediction = model.predict(preprocessed_frame)
    predicted_label = tf.argmax(prediction, axis=1).numpy()[0]
    label_map_reverse = {v: k for k, v in label_map.items()}
    predicted_label_name = label_map_reverse[predicted_label]
    return predicted_label_name

# Initialize the webcam
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    if not ret:
        break

    # Make predictions on the frame
    predicted_label = predict_frame(frame)

    # Get the current date and time
    now = datetime.now()
    current_time = now.strftime("%Y-%m-%d %H:%M:%S")

    # Display the predictions and date/time on the frame
    cv2.putText(frame, f'Predicted: {predicted_label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)
    cv2.putText(frame, f'Time: {current_time}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)

    # Display the resulting frame
    cv2.imshow('Face Detector', frame)

    # Break the loop on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()

